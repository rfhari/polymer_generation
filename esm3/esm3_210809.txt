
     active environment : /trace/group/mcgaughey/hariharr/esm3/esm_env
    active env location : /trace/group/mcgaughey/hariharr/esm3/esm_env
            shell level : 2
       user config file : /trace/home/hariharr/.condarc
 populated config files : /trace/home/hariharr/.condarc
          conda version : 23.10.0
    conda-build version : not installed
         python version : 3.11.5.final.0
       virtual packages : __archspec=1=zen3
                          __glibc=2.28=0
                          __linux=4.18.0=0
                          __unix=0=0
       base environment : /trace/group/mcgaughey/hariharr/miniconda3  (writable)
      conda av data dir : /trace/group/mcgaughey/hariharr/miniconda3/etc/conda
  conda av metadata url : None
           channel URLs : https://conda.anaconda.org/conda-forge/linux-64
                          https://conda.anaconda.org/conda-forge/noarch
                          https://repo.anaconda.com/pkgs/main/linux-64
                          https://repo.anaconda.com/pkgs/main/noarch
                          https://repo.anaconda.com/pkgs/r/linux-64
                          https://repo.anaconda.com/pkgs/r/noarch
          package cache : /trace/group/mcgaughey/hariharr/miniconda3/pkgs
                          /trace/home/hariharr/.conda/pkgs
       envs directories : /trace/group/mcgaughey/hariharr/miniconda3/envs
                          /trace/home/hariharr/.conda/envs
               platform : linux-64
             user-agent : conda/23.10.0 requests/2.31.0 CPython/3.11.5 Linux/4.18.0-477.27.1.el8_8.x86_64 rhel/8.8 glibc/2.28 solver/libmamba conda-libmamba-solver/23.11.1 libmambapy/1.5.3
                UID:GID : 2663120:100
             netrc file : None
           offline mode : False


pwd: /trace/group/mcgaughey/hariharr/esm3
Fetching 22 files:   0%|          | 0/22 [00:00<?, ?it/s]Fetching 22 files: 100%|██████████| 22/22 [00:00<00:00, 8183.28it/s]
seq token from encoding.py: False
seq tokens from esm3.py: False
before epoch protein_tensor check grad: ESMProteinTensor(sequence=tensor([172,  24,  31,  31,  31,  33, 175]), structure=None, secondary_structure=None, sasa=None, function=None, residue_annotations=None, coordinates=None, potential_sequence_of_concern=False)
im in the local esm class
sequence_tokens from esm3.py: False
sequence_embed from esm3.py: True
after epoch target output check grad: True
seq token from encoding.py: False
seq tokens from esm3.py: False
before epoch protein_tensor check grad: ESMProteinTensor(sequence=tensor([172,  24,  31,  31,  31,  33, 175]), structure=None, secondary_structure=None, sasa=None, function=None, residue_annotations=None, coordinates=None, potential_sequence_of_concern=False)
im in the local esm class
sequence_tokens from esm3.py: False
sequence_embed from esm3.py: True
after epoch target output check grad: True
seq token from encoding.py: False
seq tokens from esm3.py: False
before epoch protein_tensor check grad: ESMProteinTensor(sequence=tensor([172,  24,  31,  31,  31,  33, 175]), structure=None, secondary_structure=None, sasa=None, function=None, residue_annotations=None, coordinates=None, potential_sequence_of_concern=False)
im in the local esm class
sequence_tokens from esm3.py: False
sequence_embed from esm3.py: True
after epoch target output check grad: True
from smilesdataset: P__LiN PCCLiN
from smilesdataset: Li__CN LiCCCN
from smilesdataset: HeC__O HeCCCO
input_seq: ('P__LiN', 'Li__CN', 'HeC__O')
target_seq: ('PCCLiN', 'LiCCCN', 'HeCCCO')
protein target check grad: ESMProtein(sequence='PCCLiN', secondary_structure=None, sasa=None, function_annotations=None, coordinates=None, plddt=None, ptm=None, potential_sequence_of_concern=False)
seq token from encoding.py: False
seq tokens from esm3.py: False
protein_tensor target check grad: torch.Size([7])
protein target check grad: ESMProtein(sequence='LiCCCN', secondary_structure=None, sasa=None, function_annotations=None, coordinates=None, plddt=None, ptm=None, potential_sequence_of_concern=False)
seq token from encoding.py: False
seq tokens from esm3.py: False
protein_tensor target check grad: torch.Size([7])
protein target check grad: ESMProtein(sequence='HeCCCO', secondary_structure=None, sasa=None, function_annotations=None, coordinates=None, plddt=None, ptm=None, potential_sequence_of_concern=False)
seq token from encoding.py: False
seq tokens from esm3.py: False
protein_tensor target check grad: torch.Size([7])
within this instance ESMProtein(sequence='P__LiN', secondary_structure=None, sasa=None, function_annotations=None, coordinates=None, plddt=None, ptm=None, potential_sequence_of_concern=False)
seq token from encoding.py: False
seq tokens from esm3.py: False
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  2.06it/s]100%|██████████| 2/2 [00:00<00:00,  2.06it/s]100%|██████████| 2/2 [00:00<00:00,  2.06it/s]
im in the local esm class
sequence_tokens from esm3.py: False
sequence_embed from esm3.py: True
logits: torch.Size([1, 7, 500])
im in the local esm class
sequence_tokens from esm3.py: False
sequence_embed from esm3.py: True
logits: torch.Size([1, 7, 500])
return from iterative function: [ESMProtein(sequence='PFryLiN', secondary_structure=None, sasa=None, function_annotations=None, coordinates=None, plddt=None, ptm=None, potential_sequence_of_concern=False)]
seq token from encoding.py: False
seq tokens from esm3.py: False
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  2.11it/s]100%|██████████| 2/2 [00:00<00:00,  2.47it/s]100%|██████████| 2/2 [00:00<00:00,  2.41it/s]
im in the local esm class
sequence_tokens from esm3.py: False
sequence_embed from esm3.py: True
logits: torch.Size([1, 7, 500])
im in the local esm class
sequence_tokens from esm3.py: False
sequence_embed from esm3.py: True
logits: torch.Size([1, 7, 500])
protein seq: PtPtLiN
within this instance ESMProtein(sequence='Li__CN', secondary_structure=None, sasa=None, function_annotations=None, coordinates=None, plddt=None, ptm=None, potential_sequence_of_concern=False)
seq token from encoding.py: False
seq tokens from esm3.py: False
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.23it/s]100%|██████████| 2/2 [00:00<00:00,  3.21it/s]100%|██████████| 2/2 [00:00<00:00,  3.22it/s]
im in the local esm class
sequence_tokens from esm3.py: False
sequence_embed from esm3.py: True
logits: torch.Size([1, 7, 500])
im in the local esm class
sequence_tokens from esm3.py: False
sequence_embed from esm3.py: True
logits: torch.Size([1, 7, 500])
return from iterative function: [ESMProtein(sequence='LiRgGdCN', secondary_structure=None, sasa=None, function_annotations=None, coordinates=None, plddt=None, ptm=None, potential_sequence_of_concern=False)]
seq token from encoding.py: False
seq tokens from esm3.py: False
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.22it/s]100%|██████████| 2/2 [00:00<00:00,  3.19it/s]100%|██████████| 2/2 [00:00<00:00,  3.19it/s]
im in the local esm class
sequence_tokens from esm3.py: False
sequence_embed from esm3.py: True
logits: torch.Size([1, 7, 500])
im in the local esm class
sequence_tokens from esm3.py: False
sequence_embed from esm3.py: True
logits: torch.Size([1, 7, 500])
protein seq: LiSbDsCN
within this instance ESMProtein(sequence='HeC__O', secondary_structure=None, sasa=None, function_annotations=None, coordinates=None, plddt=None, ptm=None, potential_sequence_of_concern=False)
seq token from encoding.py: False
seq tokens from esm3.py: False
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.22it/s]100%|██████████| 2/2 [00:00<00:00,  3.19it/s]100%|██████████| 2/2 [00:00<00:00,  3.20it/s]
im in the local esm class
sequence_tokens from esm3.py: False
sequence_embed from esm3.py: True
logits: torch.Size([1, 7, 500])
im in the local esm class
sequence_tokens from esm3.py: False
sequence_embed from esm3.py: True
logits: torch.Size([1, 7, 500])
return from iterative function: [ESMProtein(sequence='HeCNpyO', secondary_structure=None, sasa=None, function_annotations=None, coordinates=None, plddt=None, ptm=None, potential_sequence_of_concern=False)]
seq token from encoding.py: False
seq tokens from esm3.py: False
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.22it/s]100%|██████████| 2/2 [00:00<00:00,  3.20it/s]100%|██████████| 2/2 [00:00<00:00,  3.20it/s]
im in the local esm class
sequence_tokens from esm3.py: False
sequence_embed from esm3.py: True
logits: torch.Size([1, 7, 500])
im in the local esm class
sequence_tokens from esm3.py: False
sequence_embed from esm3.py: True
logits: torch.Size([1, 7, 500])
protein seq: HeCmNbO
c: ['PtPtLiN', 'LiSbDsCN', 'HeCmNbO']
output seq after generation: ['PtPtLiN', 'LiSbDsCN', 'HeCmNbO']
seq token from encoding.py: False
seq tokens from esm3.py: False
im in the local esm class
sequence_tokens from esm3.py: False
sequence_embed from esm3.py: True
seq output check grad: torch.Size([1, 6, 500])
seq token from encoding.py: False
seq tokens from esm3.py: False
im in the local esm class
sequence_tokens from esm3.py: False
sequence_embed from esm3.py: True
seq output check grad: torch.Size([1, 7, 500])
seq token from encoding.py: False
seq tokens from esm3.py: False
im in the local esm class
sequence_tokens from esm3.py: False
sequence_embed from esm3.py: True
seq output check grad: torch.Size([1, 7, 500])
Output logits requires_grad: torch.Size([10500])
Target logits requires_grad: torch.Size([21])
Traceback (most recent call last):
  File "/trace/group/mcgaughey/hariharr/esm3/train_main.py", line 169, in <module>
    train_model(model, criterion, optimizer, dataset)
  File "/trace/group/mcgaughey/hariharr/esm3/train_main.py", line 122, in train_model
    loss = criterion(padded_output, padded_target)
  File "/trace/group/mcgaughey/hariharr/esm3/esm_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/trace/group/mcgaughey/hariharr/esm3/esm_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/trace/group/mcgaughey/hariharr/esm3/esm_env/lib/python3.10/site-packages/torch/nn/modules/loss.py", line 1295, in forward
    return F.cross_entropy(
  File "/trace/group/mcgaughey/hariharr/esm3/esm_env/lib/python3.10/site-packages/torch/nn/functional.py", line 3494, in cross_entropy
    return torch._C._nn.cross_entropy_loss(
RuntimeError: size mismatch (got input: [10500], target: [21])
